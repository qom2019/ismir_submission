{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from model.vae import cnn_vae_rnn\n",
    "from util.miditools import piano_roll_to_pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Setting up constants and loading the data\n",
    "##################################################################\n",
    "\n",
    "# nintendo\n",
    "nintendo_file = './Downloads/node-vgmusic-downloader/download/console/nintendo/gameboy/'\n",
    "# nottingham\n",
    "nottingham_file = './Downloads/node-vgmusic-downloader/download/console/microsoft/xbox/'\n",
    "\n",
    "# 'wget '+'http://www-etud.iro.umontreal.ca/~boulanni/JSB%20Chorales.pickle -O '\n",
    "# 'wget '+'http://www-etud.iro.umontreal.ca/~boulanni/Nottingham.pickle -O '\n",
    "# 'wget '+'http://www-etud.iro.umontreal.ca/~boulanni/MuseData.pickle -O '\n",
    "# 'wget '+'http://www-etud.iro.umontreal.ca/~boulanni/Piano-midi.de.pickle -O '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snapshot_interval = 200\n",
    "log_interval = 50\n",
    "\n",
    "checkpoint_file = './tfmodel/exp-omnibook-bigru-iter-%s-trainloss-%s-c-major.tfmodel'\n",
    "# mudb_file = '../Nottingham/preprocessing/CN_mudb_train.npz'\n",
    "# dev_file = '../Nottingham/preprocessing/CN_mudb_valid.npz'\n",
    "dev_file = '/home/eko/Downloads/Omnibook/Midi/preprocessing/mudb_train.npz'\n",
    "\n",
    "# train_data = np.load(mudb_file)\n",
    "dev_data = np.load(dev_file)\n",
    "# print range(train_data['bars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fs = train_data['fs']\n",
    "fs = dev_data['fs']\n",
    "print fs\n",
    "\n",
    "num_timesteps = int(fs)\n",
    "# bars = train_data['bars']\n",
    "devBars = dev_data['bars']\n",
    "# np.random.shuffle(bars)\n",
    "\n",
    "print devBars.shape\n",
    "# print len(bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "note_range = int(devBars.shape[2])\n",
    "\n",
    "\n",
    "T = int(train_data['T']) #16\n",
    "num_batches = int(bars.shape[0])\n",
    "\n",
    "height = num_timesteps #19\n",
    "width = note_range #128\n",
    "n_visible = note_range * num_timesteps\n",
    "n_epochs = 100\n",
    "\n",
    "z_dim = 350\n",
    "X_dim = width * height\n",
    "n_hidden = z_dim\n",
    "h_dim = z_dim\n",
    "batch_size = 32\n",
    "\n",
    "trainBarsBatch = np.reshape(devBars, (-1, T, height, width, 1))\n",
    "trainBarsBatches = []\n",
    "i = 0\n",
    "while i < trainBarsBatch.shape[0] - 32:\n",
    "    trainBarsBatches.append(trainBarsBatch[i:i+32])\n",
    "    i += 32\n",
    "devBarsBatch = np.reshape(devBars, (-1, T, height, width, 1))\n",
    "devBarsBatches = []\n",
    "i = 0\n",
    "while i < devBarsBatch.shape[0] - 32:\n",
    "    devBarsBatches.append(devBarsBatch[i:i+32])\n",
    "    i += 32\n",
    "#devBarsBatch = np.array_split(devBarsBatch, batch_size)\n",
    "initializer = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "audio_sr = 44100\n",
    "\n",
    "devLoss = True\n",
    "devInterval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Loading the model\n",
    "##################################################################\n",
    "with tf.name_scope('placeholders'):\n",
    "    z = tf.placeholder(tf.float32, shape=[None, z_dim], name=\"Generated_noise\")\n",
    "    #(batch x T x width x height x channels)\n",
    "    z_rnn_samples = tf.placeholder(tf.float32, shape=[None, T, height, width, 1], name=\"Generated_midi_input\")\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=[None, T, height, width, 1], name=\"Training_samples\")\n",
    "    kl_annealing = tf.placeholder(tf.float32, name=\"KL_annealing_multiplier\")\n",
    "\n",
    "    \n",
    "# model selection\n",
    "model = cnn_vae_rnn(X, z, z_rnn_samples, X_dim, z_dim=z_dim, h_dim=h_dim, initializer=initializer, keep_prob=1.0)\n",
    "# model = cnn_vae_rnn(X, z, z_rnn_samples, X_dim, z_dim=z_dim, h_dim=h_dim, initializer=initializer, keep_prob=1.0)\n",
    "# model = cnn_vae\n",
    "# model = cnn_rnn\n",
    "# model = vae_rnn\n",
    "# model = vae\n",
    "# model = rnn\n",
    "\n",
    "\n",
    "X_samples, out_samples, logits = (model['X_samples'], model['out_samples'], model['logits'])\n",
    "z_mu, z_logvar = (model['z_mu'], model['z_logvar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Losses\n",
    "##################################################################\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    X_labels = tf.reshape(X, [-1, width*height])\n",
    "\n",
    "    with tf.name_scope(\"cross_entropy\"):\n",
    "        recon_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=X_labels), 1)\n",
    "    with tf.name_scope(\"kl_divergence\"):\n",
    "        kl_loss = kl_annealing * 0.5 * tf.reduce_sum(tf.square(z_mu) + tf.exp(z_logvar) - z_logvar - 1.,1) \n",
    "    \n",
    "    recon_loss = tf.reduce_mean(tf.reshape(recon_loss, [-1, T]), axis=1)\n",
    "\n",
    "    loss = tf.reduce_mean(recon_loss + kl_loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Optimizer\n",
    "##################################################################\n",
    "with tf.name_scope(\"Optimizer\"):\n",
    "    solver = tf.train.AdamOptimizer()\n",
    "    grads = solver.compute_gradients(loss)\n",
    "    grads = [(tf.clip_by_norm(g, clip_norm=1), v) for g, v in grads]\n",
    "    train_op = solver.apply_gradients(grads)\n",
    "\n",
    "##################################################################\n",
    "# Logging\n",
    "##################################################################\n",
    "with tf.name_scope(\"Logging\"):\n",
    "    recon_loss_ph = tf.placeholder(tf.float32)\n",
    "    kl_loss_ph = tf.placeholder(tf.float32)\n",
    "    loss_ph = tf.placeholder(tf.float32)\n",
    "    audio_ph = tf.placeholder(tf.float32)\n",
    "\n",
    "    tf.summary.scalar(\"Reconstruction_loss\", recon_loss_ph)\n",
    "    tf.summary.scalar(\"KL_loss\", kl_loss_ph)\n",
    "    tf.summary.scalar(\"Loss\", loss_ph)\n",
    "    tf.summary.audio(\"sample_output\", audio_ph, audio_sr)\n",
    "    log_op = tf.summary.merge_all()\n",
    "\n",
    "writer = tf.summary.FileWriter('./tb/', graph=tf.get_default_graph())\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)))\n",
    "#sess = tf.Session(config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "# Run Initialization operations\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "loss_avg = 0.0\n",
    "decay = 0.99\n",
    "min_loss = 100.0\n",
    "min_dev_loss = 200.0\n",
    "time0 = time.time()\n",
    "##################################################################\n",
    "# Optimization loop\n",
    "##################################################################\n",
    "i = 0\n",
    "for e in range(n_epochs):\n",
    "    print(\"%s EPOCH %d %s\" % (\"\".join(10*[\"=\"]), e, \"\".join(10*[\"=\"])))\n",
    "    for batch in trainBarsBatches:\n",
    "        kl_an = 1.0#min(1.0, (i / 10) / 200.)\n",
    "        _,loss_out, kl, recon = sess.run([train_op, loss, kl_loss, recon_loss], feed_dict={X: batch, kl_annealing: kl_an})\n",
    "\n",
    "        if (i % log_interval) == 0:\n",
    "            loss_avg = decay*loss_avg + (1-decay)*loss_out\n",
    "            print('\\titer = %d, local_loss (cur) = %f, local_loss (avg) = %f, kl = %f'\n",
    "                % (i, loss_out, loss_avg, np.mean(kl)))\n",
    "            \n",
    "            time_spent = time.time() - time0\n",
    "            print('\\n\\tTotal time elapsed: %f sec. Average time per batch: %f sec\\n' %\n",
    "                (time_spent, time_spent / (i+1)))\n",
    "            #Random samples\n",
    "            z_in = np.random.randn(1, z_dim)\n",
    "            z_rnn_out = np.zeros((T,height,width,1))\n",
    "            first = True\n",
    "            for j in range(T):\n",
    "                z_rnn_out = np.expand_dims(z_rnn_out, axis=0)\n",
    "                samples = sess.run(X_samples, feed_dict={z: np.random.randn(1, z_dim), X: z_rnn_out})\n",
    "                frames = j + 1\n",
    "                samples = samples.reshape((-1, height, width, 1))\n",
    "                z_rnn_out = np.concatenate([samples[:frames], np.zeros((T-frames, height, width, 1))])\n",
    "            samples = samples.reshape((num_timesteps*(T), note_range))\n",
    "            thresh_S = samples >= 0.5\n",
    "            \n",
    "            pm_out = piano_roll_to_pretty_midi(thresh_S.T * 127, fs=fs)\n",
    "            midi_out = './tb/audio/test002_{0}.mid'.format(datetime.now().strftime(\"%Y.%m.%d.%H:%M:%S\"))\n",
    "            wav_out = './tb/audio/test002_{0}.wav'.format(datetime.now().strftime(\"%Y.%m.%d.%H:%M:%S\"))\n",
    "            audio = pm_out.synthesize() \n",
    "            audio = audio.reshape((1, len(audio)))\n",
    "            #Write out logs\n",
    "            summary = sess.run(log_op, feed_dict={recon_loss_ph: np.mean(recon), kl_loss_ph: np.mean(kl),\n",
    "                                                 loss_ph: loss_out, audio_ph: audio})\n",
    "            writer.add_summary(summary, i)\n",
    "        \n",
    "        if devLoss and i % devInterval == 0:\n",
    "            #dls = []\n",
    "            #for dbatch in devBarsBatches:\n",
    "            #    dev_loss_out, kl, recon = sess.run([loss, kl_loss, recon_loss], feed_dict={X: dbatch, kl_annealing: kl_an})\n",
    "            #    dls.append(dev_loss_out)\n",
    "            #dev_loss_out = sum(dls) / len(dls)\n",
    "            #print(\"Dev set loss %.2f\" % dev_loss_out)\n",
    "\n",
    "            if loss_out < min_dev_loss:\n",
    "                print(\"Saving checkpoint with train loss %d\" % loss_out)\n",
    "                min_dev_loss = loss_out\n",
    "                saver.save(sess, checkpoint_file % (i, str(int(loss_out))))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
