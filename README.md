# ismir_submission

This repository contains the source code of QOM : Query Interaction mechanism with Convolutional-recurrent Variational Autoencoder network.

# Description

Convolutional Neural Network (CNN) for capturing polyphonic musical structure,

Variational Recurrent Neural Network (VRNN) for creating polyphonic musical structure, and 

Query interaction model for interactive music generation based on music motifs/themes.

# References

[1] Samer Abdallah and Mark Plumbley. Information dynamics: patterns of expectation and surprise in the perception of music. Connection Science, 21(2-3):89–117,2009.

[2] Christopher Ariza. The interrogator as critic: The turing test and the evaluation of generative music systems. Computer Music Journal, 33(2):48–70, 2009.

[3] Nicolas Boulanger-Lewandowski, Yoshua Bengio, and Pascal Vincent. Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription. arXiv preprint arXiv:1206.6392, 2012.

[4] Jean-Pierre Briot, Gaëtan Hadjeres, and François Pachet. Deep learning techniques for music generation-a survey. arXiv preprint arXiv:1709.01620, 2017.

[5] Gino Brunner, Andres Konrad, Yuyi Wang, and Roger Wattenhofer. Midi-vae: Modeling dynamics and instrumentation of music with applications to style transfer. arXiv preprint arXiv:1809.07600, 2018.

[6] Kyunghyun Cho, Bart van Merrienboer, Çaglar Gulçehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. In EMNLP, 2014.

[7] Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron C Courville, and Yoshua Bengio. A recurrent latent variable model for sequential data. In Advances in neural information processing systems, pages 2980–2988, 2015.

[8] Hao-Wen Dong, Wen-Yi Hsiao, Li-Chia Yang, and YiHsuan Yang. Musegan: Multi-track sequential generative adversarial networks for symbolic music generation and accompaniment. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018.

[9] Douglas Eck and Juergen Schmidhuber. A first look at music composition using lstm recurrent neural networks. Istituto Dalle Molle Di Studi Sull Intelligenza Artificiale, 103, 2002.

[10] Arne Eigenfeldt, Oliver Bown, Philippe Pasquier, and Aengus Martin. Towards a taxonomy of musical metacreation: Reflections on the first musical metacreation weekend. In Proceedings of the Artificial Intelligence and Interactive Digital Entertainment (AIIDEÔø13) Conference, Boston, 2013.

[11] Otto Fabius and Joost R van Amersfoort. Variational recurrent auto-encoders. arXiv preprint arXiv:1412.6581, 2014.

[12] Gaëtan Hadjeres, François Pachet, and Frank Nielsen. Deepbach: a steerable model for bach chorales generation. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1362–1371. JMLR. org, 2017.

[13] Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. CoRR, abs/1312.6114, 2013.

[14] Eunjeong Stella Koh, Shlomo Dubnov, and Dustin Wright. Rethinking recurrent latent variable model for music composition. In 2018 IEEE 20th International Workshop on Multimedia Signal Processing (MMSP), pages 1–6. IEEE, 2018.

[15] Stefan Lattner, Maarten Grachten, and Gerhard Widmer. Imposing higher-level structure in polyphonic music generation using convolutional restricted boltzmann machines and constraints. arXiv preprint arXiv:1612.04742, 2016.

[16] Stefan Lattner, Maarten Grachten, and Gerhard Widmer. A predictive model for music based on learned interval representations. arXiv preprint arXiv:1806.08686, 2018.

[17] Gabriele Medeot, Srikanth Cherla, Katerina Kosta, Matt McVicar, S Abdalla, M Selvi, E Rex, and K Webster. Structure net: Inducing structure in generated melodies. In The 19th International Society for Music Information Retrieval Conference, 2018.

[18] Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, and Douglas Eck. A hierarchical latent vector model for learning long-term structure in music. arXiv preprint arXiv:1803.05428, 2018.

[19] Aäron Van Den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew W Senior, and Koray Kavukcuoglu. Wavenet: A generative model for raw audio. SSW, 125, 2016.

[20] Cheng-i Wang and Shlomo Dubnov. Pattern discovery from audio recordings by variable markov oracle: A music information dynamics approach. In Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on, pages 683–687. IEEE, 2015.

[21] Cheng-i Wang, Jennifer Hsu, and Shlomo Dubnov. Music pattern discovery with variable markov oracle: A unified approach to symbolic and audio representations. In ISMIR, pages 176–182, 2015.

[22] Li-Chia Yang, Szu-Yu Chou, and Yi-Hsuan Yang. Midinet: A convolutional generative adversarial network for symbolic-domain music generation. arXiv preprint arXiv:1703.10847, 2017.
